{"cells":[{"cell_type":"markdown","metadata":{"id":"OgYkrRCRec0r"},"source":["# Machine Learning workflow en PyTorch"]},{"cell_type":"markdown","metadata":{"id":"51Ug7Ug123Ip"},"source":["En este notebook vamos a cubrir un flujo de trabajo estándar de PyTorch (puede ser modificado según sea necesario, pero cubre los principales pasos).\n","\n","<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01_a_pytorch_workflow.png\" width=900 alt=\"diagrama de flujo de trabajo de pytorch\"/>\n","\n","Por ahora, usaremos este flujo de trabajo para predecir una simple línea recta, pero los pasos pueden repetirse y modificarse según el problema en el que estés trabajando.\n","\n","Específicamente, vamos a cubrir:\n","\n","| **Tema** | **Contenido** |\n","| ----- | ----- |\n","| **1. Preparación de datos** | Los datos pueden ser casi cualquier cosa, pero para empezar vamos a crear una simple línea recta |\n","| **2. Construcción del modelo** | Aquí crearemos un modelo para aprender patrones en los datos, también elegiremos una **función de pérdida**, un **optimizador** y construiremos un **bucle de entrenamiento**. |\n","| **3. Ajuste del modelo a los datos (entrenamiento)** | Ya tenemos datos y un modelo, ahora dejemos que el modelo (intente) encontrar patrones en los datos de (**entrenamiento**). |\n","| **4. Hacer predicciones y evaluar el modelo (inferencia)** | Nuestro modelo encontró patrones en los datos, comparemos sus hallazgos con los datos (**de prueba**) reales. |\n","| **5. Guardar y cargar un modelo** | Podemos querer usar nuestro modelo en otro lugar o volver a él más tarde. |\n"]},{"cell_type":"markdown","metadata":{"id":"L9EOt5cbod6l"},"source":["Ahora importemos lo que necesitaremos para este módulo.\n","\n","Vamos a obtener `torch`, `torch.nn` (`nn` significa red neuronal y este paquete contiene los componentes básicos para crear redes neuronales en PyTorch) y `matplotlib`.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":11516,"status":"ok","timestamp":1749160631420,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"},"user_tz":180},"id":"ZT_ikDC-ec0w","outputId":"500cc43b-8e3a-4486-8b80-1b858c2991dc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.6.0+cu124'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["import torch\n","from torch import nn\n","import matplotlib.pyplot as plt\n","\n","torch.__version__"]},{"cell_type":"markdown","metadata":{"id":"ci_-geIdec0w"},"source":["## 1. Datos (preparación y carga)\n","\n","Los \"datos\" pueden ser casi cualquier cosa que se puedan imaginar. Una tabla de números (como una hoja de Excel), imágenes de cualquier tipo, videos, archivos de audio como canciones o podcasts, estructuras de proteínas, texto y más.\n","\n","![el aprendizaje automático es un juego de dos partes: 1. convertir tus datos en un conjunto representativo de números y 2. construir o elegir un modelo para aprender la representación lo mejor posible](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-machine-learning-a-game-of-two-parts.png)\n","\n","El aprendizaje automático consta de dos partes:\n","1. Convertir tus datos, sean cuales sean, en números (una representación).\n","2. Elegir o construir un modelo para aprender la representación lo mejor posible.\n","\n","Para este notebook crearemos nuestros datos y, luego, les tocará a ustedes trabajar con datasets ya creados.\n","\n","Usaremos [regresión lineal](https://en.wikipedia.org/wiki/Linear_regression) para crear los datos con **parámetros** conocidos y luego usaremos PyTorch para ver si podemos construir un modelo para estimar estos parámetros usando [**descenso de gradiente**](https://en.wikipedia.org/wiki/Gradient_descent)."]},{"cell_type":"markdown","metadata":{"id":"b1ytFyUosGf5"},"source":["### Dataset y DataLoader\n","\n","Las clases `Dataset` y `DataLoader` de PyTorch destacan por su capacidad para agilizar el preprocesamiento y la carga de datos.\n","\n","La clase `Dataset` en PyTorch proporciona una interfaz para acceder a los datos. Permite definir cómo deben leerse, transformarse y accederse tus datos. La clase `DataLoader`, por otro lado, proporciona una forma eficiente de iterar sobre tu conjunto de datos en batches, lo cual es crucial para entrenar modelos.\n"]},{"cell_type":"markdown","metadata":{"id":"RUu7f4M4xRnJ"},"source":["Para crear un conjunto de datos personalizado, necesitamos definir una clase que herede de `torch.utils.data.Dataset`. Esta clase debe implementar tres métodos: `__init__`, `__len__`, y `__getitem__`.\n","\n","* `__init__`: Inicializa el conjunto de datos con cualquier atributo necesario como rutas de archivos o pasos de preprocesamiento de datos.\n","* `__len__`: Devuelve el número total de muestras en tu conjunto de datos.\n","* `__getitem__`: Recupera una muestra del conjunto de datos dado un índice."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"yI8WO6cVqEQB","executionInfo":{"status":"ok","timestamp":1749160631425,"user_tz":180,"elapsed":16,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}}},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader, random_split\n","\n","class LinearRegressionDataset(Dataset):\n","    \"\"\"Custom Dataset for Linear Regression\"\"\"\n","    def __init__(self, start=0, end=1, step=0.02, weight=0.7, bias=0.3):\n","        \"\"\"\n","        Initialize the dataset with given parameters\n","\n","        Args:\n","            start (float): Starting value for X\n","            end (float): Ending value for X\n","            step (float): Step size between X values\n","            weight (float): Weight parameter for linear function (slope)\n","            bias (float): Bias parameter for linear function (intercept)\n","        \"\"\"\n","        self.X = torch.arange(start, end, step).unsqueeze(dim=1)\n","        self.y = weight * self.X + bias\n","\n","    def __len__(self):\n","        \"\"\"Return the size of the dataset\"\"\"\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Get a sample from the dataset\"\"\"\n","        return self.X[idx], self.y[idx]\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"CxDv_VVyqnoF","executionInfo":{"status":"ok","timestamp":1749160631547,"user_tz":180,"elapsed":118,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}}},"outputs":[],"source":["full_dataset = LinearRegressionDataset(start=0, end=1, step=0.001, weight=1, bias=0)"]},{"cell_type":"markdown","metadata":{"id":"s1gL0L5HqPHn"},"source":["En el aprendizaje profundo, es fundamental separar nuestros datos en conjuntos de entrenamiento y prueba. Para manejar estos conjuntos de manera eficiente, utilizamos ```torch.utils.data.DataLoader```, que nos permite:\n","\n","1. **Procesar los datos por batches**: Optimiza el uso de memoria y acelera el entrenamiento.\n","2. **Cargar los datos de manera eficiente**: Utiliza la API de ```torch.utils.data.Dataset``` para gestionar el acceso a los datos.\n","3. **Construir minibatches**: Permite definir el tamaño de batch según nuestras necesidades.\n","\n","### Configuración de DataLoaders\n","\n","En la práctica, necesitamos dos DataLoaders diferentes:\n","\n","1. **DataLoader de Entrenamiento**:\n","   * Se configura con ```shuffle=True```\n","   * Aleatoriza las muestras en cada epoch\n","   * Ayuda a prevenir el sobreajuste (overfitting)\n","   * Asegura que la red vea combinaciones diferentes de datos en cada epoch\n","\n","2. **DataLoader de Validación**:\n","   * Se configura con ```shuffle=False```\n","   * Mantiene un orden consistente de los datos\n","\n","Vamos a crear los dos dataloaders:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"BpyB7JgHec0y","executionInfo":{"status":"ok","timestamp":1749160631560,"user_tz":180,"elapsed":6,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}}},"outputs":[],"source":["total_size = len(full_dataset)\n","train_size = int(0.8 * total_size)\n","test_size = total_size - train_size\n","\n","# Separar el dataset\n","train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n","\n","# Crear dataloaders\n","batch_size = 8\n","\n","train_loader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","test_loader = DataLoader(\n","    dataset=test_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,  # No es necesario shufflear el test\n","    num_workers=0\n",")"]},{"cell_type":"markdown","metadata":{"id":"kpA6OI5nqKzo"},"source":["Ahora vamos a querer aprender los parámetros teniendo a `X` (**features**) e `y` (**labels**)."]},{"cell_type":"markdown","metadata":{"id":"0eFsorRHec00"},"source":["## 2. Construir el modelo\n","\n","Ahora que tenemos algunos datos, vamos a construir un modelo para intentar aprender los parámetros desconocidos.\n","\n","En este caso replicaremos un modelo estándar de regresión lineal usando PyTorch puro. (Acá es donde pueden armar la arquitectura que quieran, convolucionales, RNNs)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jhcUJBFuec00","executionInfo":{"status":"ok","timestamp":1749160631664,"user_tz":180,"elapsed":99,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}}},"outputs":[],"source":["# Crear una clase de modelo de Regresión Lineal\n","class LinearRegressionModel(nn.Module): # <- casi todo en PyTorch es un nn.Module (piensa en esto como bloques de lego de redes neuronales)\n","    def __init__(self):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(1,  # <- comenzar con pesos aleatorios (esto se ajustará mientras el modelo aprende)\n","                                                dtype=torch.float),  # <- PyTorch prefiere float32 por defecto\n","                                    requires_grad=True)  # <- ¿podemos actualizar este valor con descenso de gradiente?\n","\n","        self.bias = nn.Parameter(torch.randn(1, # <- comenzar con sesgo aleatorio (esto se ajustará mientras el modelo aprende)\n","                                             dtype=torch.float), # <- PyTorch prefiere float32 por defecto\n","                                 requires_grad=True) # <- ¿podemos actualizar este valor con descenso de gradiente?\n","\n","\n","    # Forward define la pasada forward en el modelo\n","    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" son los datos de entrada (\n","        return self.weights * x + self.bias # <- esta es la fórmula de regresión lineal (y = m*x + b)"]},{"cell_type":"markdown","metadata":{"id":"xhu5wxVO7s_q"},"source":["\n","> **Más info:** Usaremos clases de Python para crear diferentes partes para construir redes neuronales. Si no están familiarizados con la notación de clases en Python, recomiendo leer varias veces la [guía de Programación Orientada a Objetos en Python 3 de Real Python](https://realpython.com/python3-object-oriented-programming/).\n"]},{"cell_type":"markdown","metadata":{"id":"iRRq3a0Gvvnl"},"source":["### Elementos esenciales para construir modelos en PyTorch\n","\n","PyTorch tiene cuatro (más o menos) módulos esenciales que puedes usar para crear casi cualquier tipo de red neuronal.\n","\n","Estos son [`torch.nn`](https://pytorch.org/docs/stable/nn.html), [`torch.optim`](https://pytorch.org/docs/stable/optim.html), [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) y [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html).\n","\n","| Módulo PyTorch | ¿Qué hace? |\n","| ----- | ----- |\n","| [`torch.nn`](https://pytorch.org/docs/stable/nn.html) | Contiene todos los bloques de construcción para grafos computacionales (esencialmente una serie de cálculos ejecutados de una manera particular). |\n","| [`torch.nn.Parameter`](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter) | Almacena tensores que pueden ser usados con `nn.Module`. Si `requires_grad=True`, los gradientes (usados para actualizar parámetros del modelo mediante [**descenso de gradiente**](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html)) se calculan automáticamente, esto se conoce frecuentemente como \"autograd\". |\n","| [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) | La clase base para todos los módulos de redes neuronales, todos los bloques de construcción para redes neuronales son subclases. Si estás construyendo una red neuronal en PyTorch, tus modelos deberían heredar de `nn.Module`. Requiere que se implemente un método `forward()`. |\n","| [`torch.optim`](https://pytorch.org/docs/stable/optim.html) | Contiene varios algoritmos de optimización (estos le dicen a los parámetros del modelo almacenados en `nn.Parameter` cómo cambiar mejor para mejorar el descenso de gradiente y a su vez reducir la pérdida). |\n","| `def forward()` | Todas las subclases de `nn.Module` requieren un método `forward()`, esto define el cálculo que se realizará en los datos pasados al `nn.Module` particular (por ejemplo, la fórmula de regresión lineal anterior). |\n","\n","Si lo anterior suena complejo, piénsalo así, casi todo en una red neuronal de PyTorch viene de `torch.nn`,\n","* `nn.Module` contiene los bloques de construcción más grandes (capas)\n","* `nn.Parameter` contiene los parámetros más pequeños como pesos y sesgos\n","* `forward()` le dice a los bloques más grandes cómo hacer cálculos en las entradas (tensores llenos de datos) dentro de los `nn.Module`(s)\n","* `torch.optim` contiene métodos de optimización sobre cómo mejorar los parámetros dentro de `nn.Parameter` para representar mejor los datos de entrada\n","\n","\n","> **Más info:** [Hoja de Trucos de PyTorch](https://pytorch.org/tutorials/beginner/ptcheat.html).\n"]},{"cell_type":"markdown","metadata":{"id":"HYt5sKsgufG7"},"source":["### Revisando el contenido de un modelo PyTorch\n","\n","Vamos a crear una instancia del modelo con la clase que creamos y revisar sus parámetros usando [`.parameters()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters)."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68,"status":"ok","timestamp":1749160631731,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"},"user_tz":180},"id":"CsEKA3A_ec01","outputId":"e9251b01-59e0-453f-a208-a7bf5d35084c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([0.3367], requires_grad=True),\n"," Parameter containing:\n"," tensor([0.1288], requires_grad=True)]"]},"metadata":{},"execution_count":6}],"source":["# Establecer semilla manual ya que nn.Parameter se inicializa aleatoriamente\n","torch.manual_seed(42)\n","\n","# Crear una instancia del modelo (esto es una subclase de nn.Module que contiene nn.Parameter(s))\n","model_0 = LinearRegressionModel()\n","\n","# Revisar los nn.Parameter(s) dentro de la subclase nn.Module que creamos\n","list(model_0.parameters())"]},{"cell_type":"markdown","metadata":{"id":"CNOmcQdSq34e"},"source":["También podemos obtener el estado (lo que contiene el modelo) del modelo usando [`.state_dict()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict).\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69,"status":"ok","timestamp":1749160631804,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"},"user_tz":180},"id":"XC1N_1Qrec01","outputId":"96ee5c56-da2d-4342-d17b-d84605012a39"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"]},"metadata":{},"execution_count":7}],"source":["model_0.state_dict()"]},{"cell_type":"markdown","metadata":{"id":"BDKdLN7nuheb"},"source":["### Haciendo predicciones usando `torch.inference_mode()`\n","\n","Podemos pasarle los datos de prueba `X_test` para ver qué tan cerca predice `y_test`.\n","\n","Cuando pasamos datos a nuestro modelo, estos pasarán por el método `forward()` del modelo y producirán un resultado usando lo que definimos.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":61,"status":"ok","timestamp":1749160631870,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"},"user_tz":180},"id":"-ITlZgU5ec02","outputId":"b125478d-201f-4112-cf5d-013affd407fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4244],\n","        [0.1601],\n","        [0.3211],\n","        [0.1655],\n","        [0.2312],\n","        [0.3854],\n","        [0.4557],\n","        [0.3823],\n","        [0.2079],\n","        [0.3847],\n","        [0.1864],\n","        [0.3352],\n","        [0.4110],\n","        [0.3591],\n","        [0.3076],\n","        [0.1413],\n","        [0.2493],\n","        [0.4318],\n","        [0.2066],\n","        [0.2652],\n","        [0.1379],\n","        [0.2009],\n","        [0.3709],\n","        [0.3860],\n","        [0.3716],\n","        [0.2568],\n","        [0.2271],\n","        [0.1288],\n","        [0.2288],\n","        [0.3248],\n","        [0.4493],\n","        [0.3911],\n","        [0.1487],\n","        [0.4301],\n","        [0.4574],\n","        [0.1430],\n","        [0.2753],\n","        [0.3557],\n","        [0.1898],\n","        [0.2615],\n","        [0.2012],\n","        [0.1985],\n","        [0.3160],\n","        [0.3302],\n","        [0.1648],\n","        [0.1807],\n","        [0.4362],\n","        [0.2982],\n","        [0.2443],\n","        [0.3093],\n","        [0.2756],\n","        [0.4477],\n","        [0.1376],\n","        [0.1446],\n","        [0.2504],\n","        [0.3918],\n","        [0.1493],\n","        [0.3790],\n","        [0.1719],\n","        [0.2941],\n","        [0.1345],\n","        [0.2901],\n","        [0.2022],\n","        [0.3426],\n","        [0.3534],\n","        [0.2823],\n","        [0.3399],\n","        [0.3988],\n","        [0.2046],\n","        [0.4264],\n","        [0.1931],\n","        [0.4372],\n","        [0.3840],\n","        [0.1992],\n","        [0.1399],\n","        [0.3655],\n","        [0.4386],\n","        [0.2998],\n","        [0.4648],\n","        [0.2238],\n","        [0.4177],\n","        [0.2497],\n","        [0.2975],\n","        [0.4463],\n","        [0.3638],\n","        [0.4207],\n","        [0.1658],\n","        [0.3278],\n","        [0.4322],\n","        [0.1938],\n","        [0.3672],\n","        [0.2972],\n","        [0.1776],\n","        [0.4571],\n","        [0.3133],\n","        [0.3615],\n","        [0.3955],\n","        [0.1961],\n","        [0.3541],\n","        [0.3197],\n","        [0.4174],\n","        [0.3891],\n","        [0.2120],\n","        [0.2042],\n","        [0.1524],\n","        [0.4160],\n","        [0.2322],\n","        [0.1820],\n","        [0.4099],\n","        [0.4096],\n","        [0.2194],\n","        [0.3982],\n","        [0.2800],\n","        [0.4642],\n","        [0.3180],\n","        [0.3268],\n","        [0.2995],\n","        [0.3200],\n","        [0.3864],\n","        [0.1756],\n","        [0.2564],\n","        [0.2988],\n","        [0.1796],\n","        [0.3817],\n","        [0.4638],\n","        [0.4544],\n","        [0.3453],\n","        [0.4500],\n","        [0.3396],\n","        [0.2339],\n","        [0.3487],\n","        [0.2945],\n","        [0.4184],\n","        [0.3009],\n","        [0.2749],\n","        [0.2177],\n","        [0.2302],\n","        [0.2884],\n","        [0.2133],\n","        [0.3052],\n","        [0.2847],\n","        [0.3938],\n","        [0.4652],\n","        [0.2935],\n","        [0.4635],\n","        [0.3025],\n","        [0.4443],\n","        [0.2719],\n","        [0.3019],\n","        [0.1924],\n","        [0.4507],\n","        [0.1881],\n","        [0.2103],\n","        [0.3120],\n","        [0.4510],\n","        [0.4126],\n","        [0.2039],\n","        [0.2413],\n","        [0.2113],\n","        [0.2207],\n","        [0.4396],\n","        [0.1941],\n","        [0.2359],\n","        [0.1541],\n","        [0.3813],\n","        [0.1736],\n","        [0.3712],\n","        [0.1409],\n","        [0.1803],\n","        [0.2796],\n","        [0.4079],\n","        [0.1561],\n","        [0.2197],\n","        [0.3904],\n","        [0.3507],\n","        [0.1295],\n","        [0.1685],\n","        [0.3574],\n","        [0.2382],\n","        [0.3830],\n","        [0.2625],\n","        [0.1935],\n","        [0.2820],\n","        [0.3298],\n","        [0.4120],\n","        [0.1857],\n","        [0.4527],\n","        [0.1706],\n","        [0.2658],\n","        [0.4335],\n","        [0.4332],\n","        [0.2160],\n","        [0.2241],\n","        [0.2423],\n","        [0.1739],\n","        [0.2605],\n","        [0.3322],\n","        [0.2234],\n","        [0.2729],\n","        [0.2860]])\n"]}],"source":["predictions = []\n","with torch.inference_mode():  # o torch.no_grad()\n","    for X_batch, y_batch in test_loader:\n","        batch_preds = model_0(X_batch)\n","        predictions.append(batch_preds)\n","\n","    y_preds = torch.cat(predictions)\n","\n","print(y_preds)\n","\n","# with torch.no_grad():\n","#   y_preds = model_0(X_test)"]},{"cell_type":"markdown","metadata":{"id":"L_Bx5I1FsIS0"},"source":["Como sugiere el nombre, `torch.inference_mode()` se usa cuando se utiliza un modelo para inferencia (hacer predicciones).\n","\n","`torch.inference_mode()` desactiva varias cosas (como el seguimiento de gradientes, que es necesario para el entrenamiento pero no para la inferencia) para hacer los **pases hacia adelante** (datos pasando por el método `forward()`) más rápidos.\n","\n","> **Nota:** En código más antiguo de PyTorch, también pueden encontrar `torch.no_grad()` siendo usado para inferencia. Aunque `torch.inference_mode()` y `torch.no_grad()` hacen cosas similares, `torch.inference_mode()` es más nuevo, potencialmente más rápido y preferido. Mira este [Tweet de PyTorch](https://twitter.com/PyTorch/status/1437838231505096708?s=20) para más información.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1749160631918,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"},"user_tz":180},"id":"k4xCScCvec02","outputId":"f457ebf3-52f0-4271-ca76-add519b0e2c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Número de muestras de prueba: 200\n","Número de predicciones realizadas: 200\n"]}],"source":["# Chequear predicciones\n","print(f\"Número de muestras de prueba: {test_size}\")\n","print(f\"Número de predicciones realizadas: {len(y_preds)}\")"]},{"cell_type":"markdown","metadata":{"id":"FnSwGbQEupZs"},"source":["Observemos cómo hay un valor de predicción por cada muestra de prueba.\n","\n","Esto es debido al tipo de datos que estamos usando. Para nuestra línea recta, un valor de `X` se corresponde con un valor de `y`.\n","\n","Sin embargo, los modelos de aprendizaje automático son muy flexibles. Podríamos tener 100 valores de `X` correspondiendo a uno, dos, tres o 10 valores de `y`. Todo depende de lo que estemos trabajando."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Mjip-vZHtTLo","executionInfo":{"status":"ok","timestamp":1749160631951,"user_tz":180,"elapsed":29,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}}},"outputs":[],"source":["y_test = torch.cat([batch[1] for batch in test_loader])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":51,"status":"ok","timestamp":1749160631998,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"},"user_tz":180},"id":"JLJWVANkhY3-","outputId":"0a124c77-0f65-4222-e743-adc8724a9592"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 4.5358e-01],\n","        [-6.7122e-02],\n","        [ 2.4994e-01],\n","        [-5.6509e-02],\n","        [ 7.2837e-02],\n","        [ 3.7663e-01],\n","        [ 5.1526e-01],\n","        [ 3.7066e-01],\n","        [ 2.7068e-02],\n","        [ 3.7531e-01],\n","        [-1.5383e-02],\n","        [ 2.7780e-01],\n","        [ 4.2704e-01],\n","        [ 3.2489e-01],\n","        [ 2.2341e-01],\n","        [-1.0427e-01],\n","        [ 1.0866e-01],\n","        [ 4.6817e-01],\n","        [ 2.4415e-02],\n","        [ 1.3983e-01],\n","        [-1.1090e-01],\n","        [ 1.3139e-02],\n","        [ 3.4811e-01],\n","        [ 3.7796e-01],\n","        [ 3.4944e-01],\n","        [ 1.2325e-01],\n","        [ 6.4877e-02],\n","        [-1.2881e-01],\n","        [ 6.8194e-02],\n","        [ 2.5724e-01],\n","        [ 5.0266e-01],\n","        [ 3.8791e-01],\n","        [-8.9674e-02],\n","        [ 4.6485e-01],\n","        [ 5.1858e-01],\n","        [-1.0095e-01],\n","        [ 1.5973e-01],\n","        [ 3.1826e-01],\n","        [-8.7504e-03],\n","        [ 1.3253e-01],\n","        [ 1.3802e-02],\n","        [ 8.4957e-03],\n","        [ 2.3999e-01],\n","        [ 2.6785e-01],\n","        [-5.7835e-02],\n","        [-2.6660e-02],\n","        [ 4.7679e-01],\n","        [ 2.0484e-01],\n","        [ 9.8706e-02],\n","        [ 2.2672e-01],\n","        [ 1.6039e-01],\n","        [ 4.9934e-01],\n","        [-1.1156e-01],\n","        [-9.7634e-02],\n","        [ 1.1065e-01],\n","        [ 3.8924e-01],\n","        [-8.8348e-02],\n","        [ 3.6403e-01],\n","        [-4.3906e-02],\n","        [ 1.9688e-01],\n","        [-1.1753e-01],\n","        [ 1.8892e-01],\n","        [ 1.5792e-02],\n","        [ 2.9239e-01],\n","        [ 3.1362e-01],\n","        [ 1.7366e-01],\n","        [ 2.8709e-01],\n","        [ 4.0316e-01],\n","        [ 2.0435e-02],\n","        [ 4.5756e-01],\n","        [-2.1173e-03],\n","        [ 4.7878e-01],\n","        [ 3.7398e-01],\n","        [ 9.8223e-03],\n","        [-1.0692e-01],\n","        [ 3.3750e-01],\n","        [ 4.8144e-01],\n","        [ 2.0815e-01],\n","        [ 5.3317e-01],\n","        [ 5.8244e-02],\n","        [ 4.4031e-01],\n","        [ 1.0932e-01],\n","        [ 2.0351e-01],\n","        [ 4.9669e-01],\n","        [ 3.3418e-01],\n","        [ 4.4628e-01],\n","        [-5.5845e-02],\n","        [ 2.6321e-01],\n","        [ 4.6883e-01],\n","        [-7.9064e-04],\n","        [ 3.4081e-01],\n","        [ 2.0285e-01],\n","        [-3.2630e-02],\n","        [ 5.1792e-01],\n","        [ 2.3468e-01],\n","        [ 3.2954e-01],\n","        [ 3.9653e-01],\n","        [ 3.8525e-03],\n","        [ 3.1494e-01],\n","        [ 2.4729e-01],\n","        [ 4.3965e-01],\n","        [ 3.8393e-01],\n","        [ 3.5028e-02],\n","        [ 1.9772e-02],\n","        [-8.2378e-02],\n","        [ 4.3699e-01],\n","        [ 7.4827e-02],\n","        [-2.4006e-02],\n","        [ 4.2505e-01],\n","        [ 4.2439e-01],\n","        [ 4.9621e-02],\n","        [ 4.0184e-01],\n","        [ 1.6902e-01],\n","        [ 5.3185e-01],\n","        [ 2.4397e-01],\n","        [ 2.6122e-01],\n","        [ 2.0749e-01],\n","        [ 2.4795e-01],\n","        [ 3.7862e-01],\n","        [-3.6609e-02],\n","        [ 1.2258e-01],\n","        [ 2.0616e-01],\n","        [-2.8650e-02],\n","        [ 3.6934e-01],\n","        [ 5.3118e-01],\n","        [ 5.1261e-01],\n","        [ 2.9770e-01],\n","        [ 5.0399e-01],\n","        [ 2.8642e-01],\n","        [ 7.8143e-02],\n","        [ 3.0433e-01],\n","        [ 1.9754e-01],\n","        [ 4.4164e-01],\n","        [ 2.1014e-01],\n","        [ 1.5907e-01],\n","        [ 4.6304e-02],\n","        [ 7.0847e-02],\n","        [ 1.8560e-01],\n","        [ 3.7681e-02],\n","        [ 2.1876e-01],\n","        [ 1.7830e-01],\n","        [ 3.9322e-01],\n","        [ 5.3384e-01],\n","        [ 1.9555e-01],\n","        [ 5.3052e-01],\n","        [ 2.1346e-01],\n","        [ 4.9271e-01],\n","        [ 1.5310e-01],\n","        [ 2.1213e-01],\n","        [-3.4439e-03],\n","        [ 5.0531e-01],\n","        [-1.2067e-02],\n","        [ 3.1712e-02],\n","        [ 2.3203e-01],\n","        [ 5.0598e-01],\n","        [ 4.3036e-01],\n","        [ 1.9109e-02],\n","        [ 9.2736e-02],\n","        [ 3.3701e-02],\n","        [ 5.2274e-02],\n","        [ 4.8343e-01],\n","        [-1.2735e-04],\n","        [ 8.2123e-02],\n","        [-7.9061e-02],\n","        [ 3.6867e-01],\n","        [-4.0589e-02],\n","        [ 3.4877e-01],\n","        [-1.0493e-01],\n","        [-2.7323e-02],\n","        [ 1.6835e-01],\n","        [ 4.2107e-01],\n","        [-7.5081e-02],\n","        [ 5.0284e-02],\n","        [ 3.8658e-01],\n","        [ 3.0831e-01],\n","        [-1.2748e-01],\n","        [-5.0539e-02],\n","        [ 3.2158e-01],\n","        [ 8.6766e-02],\n","        [ 3.7199e-01],\n","        [ 1.3452e-01],\n","        [-1.4540e-03],\n","        [ 1.7300e-01],\n","        [ 2.6719e-01],\n","        [ 4.2903e-01],\n","        [-1.6710e-02],\n","        [ 5.0929e-01],\n","        [-4.6559e-02],\n","        [ 1.4116e-01],\n","        [ 4.7149e-01],\n","        [ 4.7082e-01],\n","        [ 4.2988e-02],\n","        [ 5.8907e-02],\n","        [ 9.4726e-02],\n","        [-3.9926e-02],\n","        [ 1.3054e-01],\n","        [ 2.7183e-01],\n","        [ 5.7581e-02],\n","        [ 1.5509e-01],\n","        [ 1.8096e-01]])"]},"metadata":{},"execution_count":11}],"source":["y_test - y_preds"]},{"cell_type":"markdown","metadata":{"id":"lxt8WUzdv1qS"},"source":["Las predicciones están bastante lejos de la realidad. Esto tiene sentido cuando recordamos que nuestro modelo está usando solo valores de parámetros aleatorios para hacer predicciones.\n"]},{"cell_type":"markdown","metadata":{"id":"ZZpa-fXLec03"},"source":["## 3. Entrenar el modelo\n","\n","Ahora mismo nuestro modelo está haciendo predicciones usando parámetros aleatorios para hacer cálculos, básicamente está adivinando (al azar).\n","\n","Para arreglar esto, podemos actualizar sus parámetros internos, los valores de `weights` (pesos) y `bias` (sesgo) que establecimos aleatoriamente usando `nn.Parameter()` y `torch.randn()` para que sean algo que represente mejor los datos.\n"]},{"cell_type":"markdown","metadata":{"id":"aD8pnhJUyZUT"},"source":["### Creando una función de pérdida y un optimizador en PyTorch\n","\n","Necesitamos agregar una **función de pérdida** y un **optimizador**.\n","\n","Sus roles son:\n","\n","| Función | ¿Qué hace? | ¿Dónde se encuentra en PyTorch? | Valores comunes |\n","| ----- | ----- | ----- | ----- |\n","| **Función de pérdida** | Mide qué tan equivocadas están las predicciones de tu modelo (ej. `y_preds`) comparadas con las etiquetas verdaderas (ej. `y_test`). Mientras más bajo, mejor. | PyTorch tiene muchas funciones de pérdida incorporadas en [`torch.nn`](https://pytorch.org/docs/stable/nn.html#loss-functions). | Error absoluto medio (MAE) para problemas de regresión ([`torch.nn.L1Loss()`](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html)). Entropía cruzada binaria para problemas de clasificación binaria ([`torch.nn.BCELoss()`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)). |\n","| **Optimizador** | Le dice a nuestro modelo cómo actualizar sus parámetros internos para reducir mejor la pérdida. | Pueden encontrar varias implementaciones de funciones de optimización en [`torch.optim`](https://pytorch.org/docs/stable/optim.html). | Descenso de gradiente estocástico ([`torch.optim.SGD()`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)). Optimizador Adam ([`torch.optim.Adam()`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)). |\n","\n","\n","Para nuestro problema, ya que estamos prediciendo un número, usemos MAE (que está bajo `torch.nn.L1Loss()`) en PyTorch como nuestra función de pérdida.\n","\n","Y usaremos SGD, `torch.optim.SGD(params, lr)` donde:\n","\n","* `params` son los parámetros objetivo del modelo que nos gustaría optimizar (ej. los valores de `weights` y `bias` que establecimos aleatoriamente antes).\n","* `lr` es la **tasa de aprendizaje** a la que nos gustaría que el optimizador actualice los parámetros, más alta significa que el optimizador intentará actualizaciones más grandes (estas pueden ser a veces demasiado grandes y el optimizador fallará), más baja significa que el optimizador intentará actualizaciones más pequeñas (estas pueden ser a veces demasiado pequeñas y el optimizador tardará demasiado en encontrar los valores ideales). La tasa de aprendizaje se considera un **hiperparámetro** (porque es establecida por un ingeniero de aprendizaje automático). Los valores iniciales comunes para la tasa de aprendizaje son `0.01`, `0.001`, `0.0001`, sin embargo, estos también pueden ajustarse con el tiempo (esto se llama [programación de tasa de aprendizaje](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate))."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"P3T7hpNPec03","executionInfo":{"status":"ok","timestamp":1749160642072,"user_tz":180,"elapsed":10070,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}}},"outputs":[],"source":["# Crear la función de pérdida\n","loss_fn = nn.L1Loss() # La pérdida MAE es lo mismo que L1Loss\n","\n","# Crear el optimizador\n","optimizer = torch.optim.SGD(\n","    params=model_0.parameters(), # parámetros del modelo objetivo para optimizar\n","    lr=0.01 # tasa de aprendizaje\n","            # (cuánto debe cambiar el optimizador los parámetros en cada paso, mayor=más (menos estable), menor=menos (podría tomar mucho tiempo))\n",")"]},{"cell_type":"markdown","metadata":{"id":"aFcKCsPcRfnA"},"source":["### Creando un bucle de optimización en PyTorch\n","\n","Ahora que tenemos una función de pérdida y un optimizador, es hora de crear un **bucle de entrenamiento** (y un **bucle de prueba**).\n","\n","El bucle de entrenamiento implica que el modelo recorra los datos de entrenamiento y aprenda las relaciones entre las `features` (características) y las `labels` (etiquetas).\n","\n","El bucle de prueba implica recorrer los datos de prueba y evaluar qué tan buenos son los patrones que el modelo aprendió en los datos de entrenamiento (el modelo nunca ve los datos de prueba durante el entrenamiento)."]},{"cell_type":"markdown","metadata":{"id":"agXn72H-sgyd"},"source":["### Bucle de entrenamiento en PyTorch\n","\n","Para el bucle de entrenamiento, construiremos los siguientes pasos:\n","\n","| Número | Nombre del paso | ¿Qué hace? | Ejemplo de código |\n","| ----- | ----- | ----- | ----- |\n","| 1 | forward pass | El modelo recorre todos los datos de entrenamiento una vez, realizando los cálculos de su función `forward()`. | `model(x_train)` |\n","| 2 | Calcular la pérdida | Las salidas del modelo (predicciones) se comparan con la verdad fundamental y se evalúan para ver qué tan equivocadas están. | `loss = loss_fn(y_pred, y_train)` |\n","| 3 | Poner gradientes a cero | Los gradientes del optimizador se ponen a cero (se acumulan por defecto) para que puedan ser recalculados para el paso de entrenamiento específico. | `optimizer.zero_grad()` |\n","| 4 | Realizar retropropagación en la pérdida | Calcula el gradiente de la pérdida con respecto a cada parámetro del modelo que se actualizará (cada parámetro con `requires_grad=True`). Esto se conoce como **retropropagación** o **backpropagation**, de ahí \"backwards\". | `loss.backward()` |\n","| 5 | Actualizar el optimizador (**descenso de gradiente**) | Actualiza los parámetros con `requires_grad=True` con respecto a los gradientes de pérdida para mejorarlos. | `optimizer.step()` |\n","\n","![bucle de entrenamiento pytorch anotado](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-training-loop-annotated.png)\n","\n","> Y sobre el orden de las cosas, el anterior es un buen orden por defecto, pero puedes ver órdenes ligeramente diferentes. Algunas reglas generales:\n","> * Calcular la pérdida (`loss = ...`) *antes* de realizar la retropropagación en ella (`loss.backward()`).\n","> * Poner los gradientes a cero (`optimizer.zero_grad()`) *antes* de calcular los gradientes de la pérdida con respecto a cada parámetro del modelo (`loss.backward()`).\n","> * Dar un paso en el optimizador (`optimizer.step()`) *después* de realizar la retropropagación en la pérdida (`loss.backward()`)."]},{"cell_type":"markdown","metadata":{"id":"OXHDdlfjssDc"},"source":["### Bucle de testing en PyTorch\n","\n","En cuanto al bucle de testing (evaluación de nuestro modelo), los pasos típicos incluyen:\n","\n","| Número | Nombre del paso | ¿Qué hace? | Ejemplo de código |\n","| ----- | ----- | ----- | ----- |\n","| 1 | forward pass | El modelo recorre todos los datos de prueba una vez, realizando los cálculos de su función `forward()`. | `model(x_test)` |\n","| 2 | Calcular la pérdida | Las salidas del modelo (predicciones) se comparan con la verdad y se evalúan para ver qué tan equivocadas están. | `loss = loss_fn(y_pred, y_test)` |\n","| 3 | Calcular métricas de evaluación (opcional) | Junto con el valor de pérdida, puedes querer calcular otras métricas de evaluación como la precisión en el conjunto de prueba. | Funciones personalizadas |\n","\n","Este bucle no contiene la realización de retropropagación (`loss.backward()`) ni el paso del optimizador (`optimizer.step()`), esto es porque ningún parámetro en el modelo está siendo cambiado durante la prueba. Para las pruebas, solo nos interesa la salida del pase hacia adelante a través del modelo.\n","\n","![bucle de prueba pytorch anotado](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-testing-loop-annotated.png)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6748,"status":"ok","timestamp":1749160648794,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"},"user_tz":180},"id":"k1DfhyJ7ec03","outputId":"c41a4572-7d7b-4f66-e85a-d5a5466c58ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 | Train Loss: 0.13338 | Test Loss: 0.09890\n","Epoch: 10 | Train Loss: 0.00596 | Test Loss: 0.00596\n","Epoch: 20 | Train Loss: 0.00619 | Test Loss: 0.01175\n","Epoch: 30 | Train Loss: 0.00629 | Test Loss: 0.00551\n","Epoch: 40 | Train Loss: 0.00616 | Test Loss: 0.00782\n","Epoch: 50 | Train Loss: 0.00616 | Test Loss: 0.00370\n","Epoch: 60 | Train Loss: 0.00628 | Test Loss: 0.00098\n","Epoch: 70 | Train Loss: 0.00626 | Test Loss: 0.00815\n","Epoch: 80 | Train Loss: 0.00629 | Test Loss: 0.00221\n","Epoch: 90 | Train Loss: 0.00615 | Test Loss: 0.00631\n"]}],"source":["torch.manual_seed(42)\n","\n","epochs = 100\n","\n","# Empty lists to track values\n","train_loss_values = []\n","test_loss_values = []\n","epoch_count = []\n","\n","for epoch in range(epochs):\n","    ### Training\n","    model_0.train()\n","    train_loss = 0\n","\n","    # Loop through training batches\n","    for X_batch, y_batch in train_loader:\n","        # 1. Forward pass\n","        y_pred = model_0(X_batch)\n","\n","        # 2. Calculate loss\n","        loss = loss_fn(y_pred, y_batch)\n","\n","        # 3. Zero gradients\n","        optimizer.zero_grad()\n","\n","        # 4. Backpropagation\n","        loss.backward()\n","\n","        # 5. Update parameters\n","        optimizer.step()\n","\n","        # Accumulate batch loss\n","        train_loss += loss.item()\n","\n","    # Calculate average training loss for the epoch\n","    train_loss = train_loss / len(train_loader)\n","\n","    ### Testing\n","    model_0.eval()\n","    test_loss = 0\n","\n","    with torch.inference_mode():\n","        # Loop through test batches\n","        for X_batch, y_batch in test_loader:\n","            # 1. Forward pass on test data\n","            test_pred = model_0(X_batch)\n","\n","            # 2. Calculate test loss\n","            batch_test_loss = loss_fn(test_pred, y_batch)\n","\n","            # Accumulate batch test loss\n","            test_loss += batch_test_loss.item()\n","\n","        # Calculate average test loss for the epoch\n","        test_loss = test_loss / len(test_loader)\n","\n","    # Print progress every 10 epochs\n","    if epoch % 10 == 0:\n","        epoch_count.append(epoch)\n","        train_loss_values.append(train_loss)\n","        test_loss_values.append(test_loss)\n","        print(f\"Epoch: {epoch} | Train Loss: {train_loss:.5f} | Test Loss: {test_loss:.5f}\")"]},{"cell_type":"markdown","metadata":{"id":"lmqQE8Kpec04"},"source":["\n","Vamos a inspeccionar el [`.state_dict()`](https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html) de nuestro modelo para ver qué tan cerca llega nuestro modelo a los valores originales que establecimos para los pesos y el sesgo.\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1749160648839,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"},"user_tz":180},"id":"Ci0W7kn5ec04","outputId":"07ee933b-37f5-4fdf-8eae-e39bc024343c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Parámetros del modelo:\n","OrderedDict([('weights', tensor([1.0059])), ('bias', tensor([0.0013]))])\n","\n","Valores originales:\n","weights: 1.0, bias: 0.0\n"]}],"source":["# Revisar los parámetros del modelo\n","print(\"\\nParámetros del modelo:\")\n","print(model_0.state_dict())\n","\n","print(\"\\nValores originales:\")\n","print(f\"weights: 1.0, bias: 0.0\")"]},{"cell_type":"markdown","metadata":{"id":"c-VBDFd2ec05"},"source":["## 4. Haciendo predicciones con un modelo PyTorch entrenado (inferencia)\n","\n","Una vez que entrenamos un modelo, queremos hacer predicciones con él.\n","\n","Hay tres cosas para recordar cuando se hacen predicciones (también llamado realizar inferencia) con un modelo PyTorch:\n","\n","1. Establecer el modelo en modo evaluación (`model.eval()`).\n","2. Hacer las predicciones usando `with torch.inference_mode(): ...`.\n","3. Todas las predicciones deben hacerse con objetos en el mismo dispositivo (por ejemplo, datos y modelo solo en GPU o datos y modelo solo en CPU).\n","\n","Los primeros dos elementos aseguran que todos los cálculos y configuraciones útiles que PyTorch usa detrás de escenas durante el entrenamiento, pero que no son necesarios para la inferencia, estén desactivados (esto resulta en un cómputo más rápido). Y el tercero asegura que no te encontrarás con errores entre dispositivos."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"xKKxSBVuec05","executionInfo":{"status":"ok","timestamp":1749160648879,"user_tz":180,"elapsed":35,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}}},"outputs":[],"source":["# 1. Establecer el modelo en modo evaluación\n","model_0.eval()\n","\n","# 2. Calcular predicciones\n","with torch.inference_mode():\n","    predictions = []\n","    true_values = []\n","\n","    for X_batch, y_batch in test_loader:\n","        # Opcional: Mover los datos al dispositivo necesario\n","        # X_batch = X_batch.to(device)\n","        # y_batch = y_batch.to(device)\n","\n","        # Inferencia\n","        batch_preds = model_0(X_batch)\n","\n","        # Guardar predicciones y real\n","        predictions.append(batch_preds)\n","        true_values.append(y_batch)\n","\n","    # Combinar las predicciones de todos los batches\n","    y_preds = torch.cat(predictions)\n","    y_test = torch.cat(true_values)"]},{"cell_type":"markdown","metadata":{"id":"8NRng9aEec05"},"source":["## 5. Guardando y cargando un modelo PyTorch\n","\n","Si entrenamos un modelo PyTorch, es probable que queramos guardarlo y exportarlo a algún lugar.\n","\n","Para guardar y cargar modelos en PyTorch, hay tres métodos principales que deberiamos conocer (todo lo siguiente viene de la [guía de guardado y carga de modelos de PyTorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference)):\n","\n","| Método PyTorch | ¿Qué hace? |\n","| ----- | ----- |\n","| [`torch.save`](https://pytorch.org/docs/stable/torch.html?highlight=save#torch.save) | Guarda un objeto serializado en el disco usando la utilidad [`pickle`](https://docs.python.org/3/library/pickle.html) de Python. Los modelos, tensores y varios otros objetos de Python como diccionarios pueden guardarse usando `torch.save`. |\n","| [`torch.load`](https://pytorch.org/docs/stable/torch.html?highlight=torch%20load#torch.load) | Usa las características de despickling de `pickle` para deserializar y cargar archivos de objetos Python guardados (como modelos, tensores o diccionarios) en la memoria. También puedes establecer a qué dispositivo cargar el objeto (CPU, GPU, etc.). |\n","| [`torch.nn.Module.load_state_dict`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=load_state_dict#torch.nn.Module.load_state_dict) | Carga el diccionario de parámetros de un modelo (`model.state_dict()`) usando un objeto `state_dict()` guardado. |\n"]},{"cell_type":"markdown","metadata":{"id":"SdAGcH2aec05"},"source":["### Guardando el `state_dict()` de un modelo PyTorch\n","\n","La [forma recomendada](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference) para guardar y cargar un modelo para inferencia (hacer predicciones) es guardando y cargando el `state_dict()` del modelo.\n","\n","Veamos cómo podemos hacer esto en algunos pasos:\n","\n","1. Crearemos un directorio llamado `models` para guardar modelos usando el módulo `pathlib` de Python.\n","2. Crearemos una ruta de archivo para guardar el modelo.\n","3. Llamaremos a `torch.save(obj, f)` donde `obj` es el `state_dict()` del modelo objetivo y `f` es el nombre del archivo donde guardar el modelo.\n","\n","> **Nota:** Es una convención común que los modelos u objetos guardados de PyTorch terminen con `.pt` o `.pth`, como `saved_model_01.pth`."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"qsQhY2S2jv90","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749160648917,"user_tz":180,"elapsed":34,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}},"outputId":"ec376b4c-a0d2-4520-9fa0-56b320daf567"},"outputs":[{"output_type":"stream","name":"stdout","text":["Guardando modelo en: models/modelo_regresion_01.pth\n"]}],"source":["# 1. Crear un directorio para guardar modelos\n","from pathlib import Path\n","MODEL_PATH = Path(\"models\")\n","MODEL_PATH.mkdir(parents=True, exist_ok=True)\n","\n","# 2. Crear nombre de archivo para guardar el modelo\n","MODEL_NAME = \"modelo_regresion_01.pth\"\n","MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n","\n","# 3. Guardar el state_dict del modelo\n","print(f\"Guardando modelo en: {MODEL_SAVE_PATH}\")\n","torch.save(obj=model_0.state_dict(),\n","          f=MODEL_SAVE_PATH)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"mpQc45zwec06","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749160649001,"user_tz":180,"elapsed":82,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}},"outputId":"814bea2d-5b87-419d-ea5b-a31dfb774692"},"outputs":[{"output_type":"stream","name":"stdout","text":["-rw-r--r-- 1 root root 1568 Jun  5 21:57 models/modelo_regresion_01.pth\n"]}],"source":["# Chequear que esta guardado\n","!ls -l models/modelo_regresion_01.pth"]},{"cell_type":"markdown","metadata":{"id":"jFQpRoH5ec06"},"source":["### Cargando el `state_dict()` de un modelo PyTorch guardado\n","\n","Tenemos un `state_dict()` guardado en `models/models/modelo_regresion_01.pth`, podemos cargarlo usando `torch.nn.Module.load_state_dict(torch.load(f))` donde `f` es la ruta del archivo de nuestro `state_dict()` guardado.\n","\n","¿Por qué llamar a `torch.load()` dentro de `torch.nn.Module.load_state_dict()`?\n","\n","Porque solo guardamos el `state_dict()` del modelo, que es un diccionario de parámetros aprendidos y no el modelo *completo*, primero tenemos que cargar el `state_dict()` con `torch.load()` y luego pasar ese `state_dict()` a una nueva instancia de nuestro modelo (que es una subclase de `nn.Module`).\n","\n","Vamos a probarlo creando otra instancia de `LinearRegressionModel()`, que es una subclase de `torch.nn.Module` y por lo tanto tendrá el método incorporado `load_state_dict()`."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"1xnh3cFDec06","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749160649142,"user_tz":180,"elapsed":138,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}},"outputId":"b844f04c-2796-41fa-a113-1dd00f802343"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":18}],"source":["# Crear una nueva instancia de nuestro modelo (esto se iniciará con pesos aleatorios)\n","loaded_model_0 = LinearRegressionModel()\n","\n","# Cargar el state_dict de nuestro modelo guardado (esto actualizará la nueva instancia de nuestro modelo con los pesos entrenados)\n","loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Ps-AuJqkec06","executionInfo":{"status":"ok","timestamp":1749160649172,"user_tz":180,"elapsed":26,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}}},"outputs":[],"source":["# 1. Poner el modelo cargado en modo evaluación\n","loaded_model_0.eval()\n","\n","# 2. Usar el administrador de contexto de modo inferencia para hacer predicciones\n","with torch.inference_mode():\n","    loaded_model_preds = []\n","\n","    for X_batch, y_batch in test_loader:\n","\n","      loaded_model_preds_batch = loaded_model_0(X_batch) # realizar un pase hacia adelante en los datos de prueba con el modelo cargado\n","      loaded_model_preds.append(loaded_model_preds_batch)\n","\n","loaded_model_preds = torch.cat(loaded_model_preds)"]},{"cell_type":"markdown","metadata":{"id":"e81XpN8WSSqn"},"source":["Ahora veamos si son las mismas que las predicciones anteriores.\n"]},{"cell_type":"code","execution_count":20,"metadata":{"collapsed":true,"id":"il9gqj6Nec06","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749160649253,"user_tz":180,"elapsed":85,"user":{"displayName":"Santiago Drelewicz","userId":"01498809559042980514"}},"outputId":"bbe84e18-3fa2-45d8-c442-0b0c96796c32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicciones previas:\n","tensor([[0.8845],\n","        [0.0949],\n","        [0.5757],\n","        [0.1109],\n","        [0.3071],\n","        [0.7678],\n","        [0.9780],\n","        [0.7587],\n","        [0.2377],\n","        [0.7658],\n","        [0.1733],\n","        [0.6179],\n","        [0.8442],\n","        [0.6893],\n","        [0.5354],\n","        [0.0385],\n","        [0.3614],\n","        [0.9066],\n","        [0.2337],\n","        [0.4087],\n","        [0.0285],\n","        [0.2166],\n","        [0.7245],\n","        [0.7698],\n","        [0.7265],\n","        [0.3835],\n","        [0.2950],\n","        [0.0013],\n","        [0.3001],\n","        [0.5867],\n","        [0.9589],\n","        [0.7849],\n","        [0.0607],\n","        [0.9016],\n","        [0.9830],\n","        [0.0436],\n","        [0.4389],\n","        [0.6793],\n","        [0.1834],\n","        [0.3976],\n","        [0.2176],\n","        [0.2095],\n","        [0.5606],\n","        [0.6028],\n","        [0.1089],\n","        [0.1562],\n","        [0.9197],\n","        [0.5073],\n","        [0.3463],\n","        [0.5405],\n","        [0.4399],\n","        [0.9539],\n","        [0.0275],\n","        [0.0486],\n","        [0.3644],\n","        [0.7869],\n","        [0.0627],\n","        [0.7487],\n","        [0.1301],\n","        [0.4952],\n","        [0.0184],\n","        [0.4831],\n","        [0.2206],\n","        [0.6400],\n","        [0.6722],\n","        [0.4600],\n","        [0.6320],\n","        [0.8080],\n","        [0.2276],\n","        [0.8905],\n","        [0.1934],\n","        [0.9227],\n","        [0.7638],\n","        [0.2115],\n","        [0.0345],\n","        [0.7084],\n","        [0.9267],\n","        [0.5123],\n","        [1.0052],\n","        [0.2850],\n","        [0.8644],\n","        [0.3624],\n","        [0.5053],\n","        [0.9499],\n","        [0.7034],\n","        [0.8734],\n","        [0.1120],\n","        [0.5958],\n","        [0.9076],\n","        [0.1954],\n","        [0.7135],\n","        [0.5042],\n","        [0.1472],\n","        [0.9820],\n","        [0.5525],\n","        [0.6964],\n","        [0.7980],\n","        [0.2025],\n","        [0.6742],\n","        [0.5716],\n","        [0.8633],\n","        [0.7789],\n","        [0.2498],\n","        [0.2266],\n","        [0.0717],\n","        [0.8593],\n","        [0.3101],\n","        [0.1602],\n","        [0.8412],\n","        [0.8402],\n","        [0.2719],\n","        [0.8060],\n","        [0.4529],\n","        [1.0032],\n","        [0.5666],\n","        [0.5928],\n","        [0.5113],\n","        [0.5726],\n","        [0.7708],\n","        [0.1411],\n","        [0.3825],\n","        [0.5093],\n","        [0.1532],\n","        [0.7567],\n","        [1.0022],\n","        [0.9740],\n","        [0.6481],\n","        [0.9609],\n","        [0.6310],\n","        [0.3151],\n","        [0.6581],\n","        [0.4962],\n","        [0.8664],\n","        [0.5153],\n","        [0.4379],\n","        [0.2669],\n","        [0.3041],\n","        [0.4781],\n","        [0.2538],\n","        [0.5284],\n","        [0.4670],\n","        [0.7929],\n","        [1.0062],\n","        [0.4932],\n","        [1.0011],\n","        [0.5203],\n","        [0.9438],\n","        [0.4288],\n","        [0.5183],\n","        [0.1914],\n","        [0.9629],\n","        [0.1783],\n","        [0.2447],\n","        [0.5485],\n","        [0.9639],\n","        [0.8493],\n","        [0.2256],\n","        [0.3373],\n","        [0.2477],\n","        [0.2759],\n","        [0.9297],\n","        [0.1964],\n","        [0.3212],\n","        [0.0768],\n","        [0.7557],\n","        [0.1351],\n","        [0.7255],\n","        [0.0375],\n","        [0.1552],\n","        [0.4519],\n","        [0.8352],\n","        [0.0828],\n","        [0.2729],\n","        [0.7829],\n","        [0.6642],\n","        [0.0033],\n","        [0.1200],\n","        [0.6843],\n","        [0.3282],\n","        [0.7607],\n","        [0.4006],\n","        [0.1944],\n","        [0.4590],\n","        [0.6018],\n","        [0.8473],\n","        [0.1713],\n","        [0.9690],\n","        [0.1260],\n","        [0.4107],\n","        [0.9116],\n","        [0.9106],\n","        [0.2618],\n","        [0.2860],\n","        [0.3403],\n","        [0.1361],\n","        [0.3946],\n","        [0.6089],\n","        [0.2840],\n","        [0.4318],\n","        [0.4711]])\n","\n","Predicciones del modelo cargado:\n","tensor([[0.8845],\n","        [0.0949],\n","        [0.5757],\n","        [0.1109],\n","        [0.3071],\n","        [0.7678],\n","        [0.9780],\n","        [0.7587],\n","        [0.2377],\n","        [0.7658],\n","        [0.1733],\n","        [0.6179],\n","        [0.8442],\n","        [0.6893],\n","        [0.5354],\n","        [0.0385],\n","        [0.3614],\n","        [0.9066],\n","        [0.2337],\n","        [0.4087],\n","        [0.0285],\n","        [0.2166],\n","        [0.7245],\n","        [0.7698],\n","        [0.7265],\n","        [0.3835],\n","        [0.2950],\n","        [0.0013],\n","        [0.3001],\n","        [0.5867],\n","        [0.9589],\n","        [0.7849],\n","        [0.0607],\n","        [0.9016],\n","        [0.9830],\n","        [0.0436],\n","        [0.4389],\n","        [0.6793],\n","        [0.1834],\n","        [0.3976],\n","        [0.2176],\n","        [0.2095],\n","        [0.5606],\n","        [0.6028],\n","        [0.1089],\n","        [0.1562],\n","        [0.9197],\n","        [0.5073],\n","        [0.3463],\n","        [0.5405],\n","        [0.4399],\n","        [0.9539],\n","        [0.0275],\n","        [0.0486],\n","        [0.3644],\n","        [0.7869],\n","        [0.0627],\n","        [0.7487],\n","        [0.1301],\n","        [0.4952],\n","        [0.0184],\n","        [0.4831],\n","        [0.2206],\n","        [0.6400],\n","        [0.6722],\n","        [0.4600],\n","        [0.6320],\n","        [0.8080],\n","        [0.2276],\n","        [0.8905],\n","        [0.1934],\n","        [0.9227],\n","        [0.7638],\n","        [0.2115],\n","        [0.0345],\n","        [0.7084],\n","        [0.9267],\n","        [0.5123],\n","        [1.0052],\n","        [0.2850],\n","        [0.8644],\n","        [0.3624],\n","        [0.5053],\n","        [0.9499],\n","        [0.7034],\n","        [0.8734],\n","        [0.1120],\n","        [0.5958],\n","        [0.9076],\n","        [0.1954],\n","        [0.7135],\n","        [0.5042],\n","        [0.1472],\n","        [0.9820],\n","        [0.5525],\n","        [0.6964],\n","        [0.7980],\n","        [0.2025],\n","        [0.6742],\n","        [0.5716],\n","        [0.8633],\n","        [0.7789],\n","        [0.2498],\n","        [0.2266],\n","        [0.0717],\n","        [0.8593],\n","        [0.3101],\n","        [0.1602],\n","        [0.8412],\n","        [0.8402],\n","        [0.2719],\n","        [0.8060],\n","        [0.4529],\n","        [1.0032],\n","        [0.5666],\n","        [0.5928],\n","        [0.5113],\n","        [0.5726],\n","        [0.7708],\n","        [0.1411],\n","        [0.3825],\n","        [0.5093],\n","        [0.1532],\n","        [0.7567],\n","        [1.0022],\n","        [0.9740],\n","        [0.6481],\n","        [0.9609],\n","        [0.6310],\n","        [0.3151],\n","        [0.6581],\n","        [0.4962],\n","        [0.8664],\n","        [0.5153],\n","        [0.4379],\n","        [0.2669],\n","        [0.3041],\n","        [0.4781],\n","        [0.2538],\n","        [0.5284],\n","        [0.4670],\n","        [0.7929],\n","        [1.0062],\n","        [0.4932],\n","        [1.0011],\n","        [0.5203],\n","        [0.9438],\n","        [0.4288],\n","        [0.5183],\n","        [0.1914],\n","        [0.9629],\n","        [0.1783],\n","        [0.2447],\n","        [0.5485],\n","        [0.9639],\n","        [0.8493],\n","        [0.2256],\n","        [0.3373],\n","        [0.2477],\n","        [0.2759],\n","        [0.9297],\n","        [0.1964],\n","        [0.3212],\n","        [0.0768],\n","        [0.7557],\n","        [0.1351],\n","        [0.7255],\n","        [0.0375],\n","        [0.1552],\n","        [0.4519],\n","        [0.8352],\n","        [0.0828],\n","        [0.2729],\n","        [0.7829],\n","        [0.6642],\n","        [0.0033],\n","        [0.1200],\n","        [0.6843],\n","        [0.3282],\n","        [0.7607],\n","        [0.4006],\n","        [0.1944],\n","        [0.4590],\n","        [0.6018],\n","        [0.8473],\n","        [0.1713],\n","        [0.9690],\n","        [0.1260],\n","        [0.4107],\n","        [0.9116],\n","        [0.9106],\n","        [0.2618],\n","        [0.2860],\n","        [0.3403],\n","        [0.1361],\n","        [0.3946],\n","        [0.6089],\n","        [0.2840],\n","        [0.4318],\n","        [0.4711]])\n","\n","¿Son iguales?: True\n"]}],"source":["# Comparar las predicciones del modelo anterior con las predicciones del modelo cargado (deberían ser las mismas)\n","print(f\"Predicciones previas:\\n{y_preds}\\n\")\n","print(f\"Predicciones del modelo cargado:\\n{loaded_model_preds}\\n\")\n","print(f\"¿Son iguales?: {torch.all(torch.eq(y_preds, loaded_model_preds))}\")"]},{"cell_type":"markdown","metadata":{"id":"Ef_tquDLcSCf"},"source":["## 6. Tarea"]}],"metadata":{"colab":{"provenance":[{"file_id":"1U4bRIsdTXMcvjsk3G7D2-r0NmMCcbwpF","timestamp":1749159542970}]},"interpreter":{"hash":"3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}